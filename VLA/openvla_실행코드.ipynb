{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1dd60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /home/lab/anaconda3/lib/python3.11/site-packages (2.7.4.post1)\n",
      "Requirement already satisfied: torch in /home/lab/anaconda3/lib/python3.11/site-packages (from flash-attn) (2.4.1)\n",
      "Requirement already satisfied: einops in /home/lab/anaconda3/lib/python3.11/site-packages (from flash-attn) (0.8.1)\n",
      "Requirement already satisfied: filelock in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/lab/anaconda3/lib/python3.11/site-packages (from torch->flash-attn) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/lab/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.8.61)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lab/anaconda3/lib/python3.11/site-packages (from jinja2->torch->flash-attn) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/lab/anaconda3/lib/python3.11/site-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e07b24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lab/anaconda3/bin/pip\", line 7, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
      "    from pip._internal.build_env import get_runnable_pip\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/build_env.py\", line 21, in <module>\n",
      "    from pip._internal.metadata import get_default_environment, get_environment\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/metadata/__init__.py\", line 9, in <module>\n",
      "    from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/metadata/base.py\", line 101, in <module>\n",
      "    class RequiresEntry(NamedTuple):\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/typing.py\", line 2891, in __new__\n",
      "    nm_tpl = _make_nmtuple(typename, types.items(),\n",
      "                                     ^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lab/anaconda3/bin/pip\", line 7, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
      "    from pip._internal.build_env import get_runnable_pip\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
      "    from pip._internal.cli.spinners import open_spinner\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
      "    from pip._internal.utils.logging import get_indentation\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/utils/logging.py\", line 29, in <module>\n",
      "    from pip._internal.utils.misc import ensure_dir\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/utils/misc.py\", line 40, in <module>\n",
      "    from pip._internal.exceptions import CommandError, ExternallyManagedEnvironment\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_internal/exceptions.py\", line 18, in <module>\n",
      "    from pip._vendor.requests.models import Request, Response\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/requests/__init__.py\", line 43, in <module>\n",
      "    from pip._vendor import urllib3\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/__init__.py\", line 11, in <module>\n",
      "    from . import exceptions\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/exceptions.py\", line 3, in <module>\n",
      "    from .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/packages/six.py\", line 192, in find_spec\n",
      "    return spec_from_loader(fullname, self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 441, in spec_from_loader\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/packages/six.py\", line 222, in is_package\n",
      "    return hasattr(self.__get_module(fullname), \"__path__\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/packages/six.py\", line 121, in __getattr__\n",
      "    _module = self._resolve()\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/packages/six.py\", line 118, in _resolve\n",
      "    return _import_module(self.mod)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/packages/six.py\", line 87, in _import_module\n",
      "    __import__(name)\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/http/client.py\", line 71, in <module>\n",
      "    import email.parser\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/email/parser.py\", line 12, in <module>\n",
      "    from email.feedparser import FeedParser, BytesFeedParser\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/email/feedparser.py\", line 27, in <module>\n",
      "    from email._policybase import compat32\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/email/_policybase.py\", line 7, in <module>\n",
      "    from email import header\n",
      "  File \"/home/lab/anaconda3/lib/python3.11/email/header.py\", line 16, in <module>\n",
      "    import email.quoprimime\n",
      "  File \"<frozen importlib._bootstrap>\", line 1173, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 170, in __enter__\n",
      "  File \"<frozen importlib._bootstrap>\", line 209, in _get_module_lock\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d215bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\r\n",
      "Built on Thu_Nov_18_09:45:30_PST_2021\r\n",
      "Cuda compilation tools, release 11.5, V11.5.119\r\n",
      "Build cuda_11.5.r11.5/compiler.30672275_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac3007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 18:27:17.044688: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742549237.061467    2988 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742549237.066474    2988 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 18:27:17.086556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 1. 필요한 라이브러리 임포트\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ef5de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# 2. 프로세서와 VLA 모델 로드 (GPU 사용, flash_attention 옵션 포함)\n",
    "processor = AutoProcessor.from_pretrained(\"openvla/openvla-7b\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf02113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected `transformers==4.40.1` and `tokenizers==0.19.1` but got `transformers==4.49.0` and `tokenizers==0.21.0`; there might be inference-time regressions due to dependency changes. If in doubt, pleaseuse the above versions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d34c3b7662b411d8425b3ff34ab8186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# 4비트 양자화 설정 (quantization_config)\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # 일반적으로 'nf4'가 사용되지만, 'fp4' 등 옵션이 있음\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # bfloat16 또는 float16 선택 가능\n",
    "    bnb_4bit_use_double_quant=True  # 이 옵션은 양자화 정확도를 높여줌\n",
    ")\n",
    "\n",
    "# 모델 로드 (4비트 양자화 적용)\n",
    "vla = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"openvla/openvla-7b\",\n",
    "    attn_implementation=\"flash_attention_2\",  # Flash Attention 2 옵션 사용\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quant_config\n",
    ").to(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9127b27",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (c10::BFloat16) and bias type (c10::Half) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(prompt, image)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 6. 모델을 이용해 action 예측 (7-DoF; BridgeV2를 위한 un-normalize 옵션 포함)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m action \u001b[38;5;241m=\u001b[39m vla\u001b[38;5;241m.\u001b[39mpredict_action(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, unnorm_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbridge_orig\u001b[39m\u001b[38;5;124m\"\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 7. 예측된 action 출력\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Action:\u001b[39m\u001b[38;5;124m\"\u001b[39m, action)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py:518\u001b[0m, in \u001b[0;36mOpenVLAForActionPrediction.predict_action\u001b[0;34m(self, input_ids, unnorm_key, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    514\u001b[0m         (input_ids, torch\u001b[38;5;241m.\u001b[39munsqueeze(torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m29871\u001b[39m])\u001b[38;5;241m.\u001b[39mlong(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(input_ids\u001b[38;5;241m.\u001b[39mdevice)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    515\u001b[0m     )\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# Run VLA inference\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(input_ids, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_action_dim(unnorm_key), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m# Extract predicted action tokens and translate into (normalized) continuous actions\u001b[39;00m\n\u001b[1;32m    521\u001b[0m predicted_action_token_ids \u001b[38;5;241m=\u001b[39m generated_ids[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_action_dim(unnorm_key) :]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2220\u001b[0m     )\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[1;32m   2224\u001b[0m         input_ids,\n\u001b[1;32m   2225\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   2226\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   2227\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   2228\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[1;32m   2229\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2231\u001b[0m     )\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2243\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:3211\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3211\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py:366\u001b[0m, in \u001b[0;36mPrismaticForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, pixel_values, labels, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, output_projector_features, return_dict)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected key `past_key_values` provided during language-only forward!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Visual Feature Extraction\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m patch_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_backbone(pixel_values)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# Projection Logic =>> Update Attention Mask\u001b[39;00m\n\u001b[1;32m    369\u001b[0m projected_patch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojector(patch_features)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py:121\u001b[0m, in \u001b[0;36mPrismaticVisionBackbone.forward\u001b[0;34m(self, pixel_values)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Split `pixel_values :: [bsz, 2 * 3, resolution, resolution]` =>> featurize =>> channel stack\u001b[39;00m\n\u001b[1;32m    120\u001b[0m img, img_fused \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(pixel_values, [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m patches, patches_fused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeaturizer(img), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused_featurizer(img_fused)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([patches, patches_fused], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py:43\u001b[0m, in \u001b[0;36munpack_tuple.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 43\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/timm/models/vision_transformer.py:663\u001b[0m, in \u001b[0;36mVisionTransformer.get_intermediate_layers\u001b[0;34m(self, x, n, reshape, return_prefix_tokens, norm)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Intermediate layer accessor (NOTE: This is a WIP experiment).\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03mInspired by DINO / DINOv2 interface\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# take last n blocks if n is an int, if in is a sequence, select by matching indices\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intermediate_layers(x, n)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    665\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(out) \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/timm/models/vision_transformer.py:640\u001b[0m, in \u001b[0;36mVisionTransformer._intermediate_layers\u001b[0;34m(self, x, n)\u001b[0m\n\u001b[1;32m    637\u001b[0m take_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_blocks \u001b[38;5;241m-\u001b[39m n, num_blocks) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m n)\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)\n\u001b[1;32m    641\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_embed(x)\n\u001b[1;32m    642\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_drop(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/timm/layers/patch_embed.py:87\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m     pad_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m W \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     86\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, pad_w, \u001b[38;5;241m0\u001b[39m, pad_h))\n\u001b[0;32m---> 87\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten:\n\u001b[1;32m     89\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NCHW -> NLC\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (c10::BFloat16) and bias type (c10::Half) should be the same"
     ]
    }
   ],
   "source": [
    "# 3. 이미지 파일 로드 (경로: /Desktop/hello.png)\n",
    "image_path = \"/home/lab/Desktop/Screensho.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# 4. 프롬프트 설정 (실제 상황에 맞는 지시문으로 수정 가능)\n",
    "prompt = \"In: What action should the robot take to pick up the object?\\nOut:\"\n",
    "\n",
    "# 5. 프롬프트와 이미지를 모델 입력 형식으로 전처리 후 GPU로 이동\n",
    "inputs = processor(prompt, image).to(\"cuda:0\", dtype=torch.bfloat16)\n",
    "\n",
    "# 6. 모델을 이용해 action 예측 (7-DoF; BridgeV2를 위한 un-normalize 옵션 포함)\n",
    "action = vla.predict_action(**inputs, unnorm_key=\"bridge_orig\", do_sample=False)\n",
    "\n",
    "# 7. 예측된 action 출력\n",
    "print(\"Predicted Action:\", action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd988f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lab/Desktop/openlva'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2c688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 18:38:13.342019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742549893.360576    4447 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742549893.365687    4447 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 18:38:13.384707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Expected `transformers==4.40.1` and `tokenizers==0.19.1` but got `transformers==4.49.0` and `tokenizers==0.21.0`; there might be inference-time regressions due to dependency changes. If in doubt, pleaseuse the above versions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a3c60652a549af8c73e183f422e75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Action: [ 0.00158061 -0.00689932  0.00131771  0.02732067 -0.00412992 -0.00329031\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 4비트(int4) 양자화 설정: 계산은 bf16로 수행\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",              # 일반적으로 'nf4' 사용\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,   # 계산 시 bf16 사용\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# 모델 로드 시 torch_dtype를 bf16으로 지정하여, 모델 전체가 bf16으로 실행되도록 함\n",
    "vla = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"openvla/openvla-7b\",\n",
    "    attn_implementation=\"flash_attention_2\",  # Flash Attention 2 옵션 사용\n",
    "    quantization_config=quant_config,         # 4비트 양자화 옵션 적용\n",
    "    torch_dtype=torch.bfloat16,               # 모델의 데이터 타입을 bf16으로 강제\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "# 프로세서 로드\n",
    "processor = AutoProcessor.from_pretrained(\"openvla/openvla-7b\", trust_remote_code=True)\n",
    "\n",
    "# 이미지 파일 로드\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebf0c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Action: [ 0.00158061 -0.00689932  0.00131771  0.02732067 -0.00412992 -0.00329031\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "image_path = \"/home/lab/Desktop/Screensho.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = \"In: What action should the robot take to pick up the object?\\nOut:\"\n",
    "\n",
    "# 프롬프트와 이미지를 모델 입력 형식으로 전처리 후 GPU로 이동 (dtype bf16)\n",
    "inputs = processor(prompt, image).to(\"cuda:0\", dtype=torch.bfloat16)\n",
    "\n",
    "# 모델을 이용해 action 예측\n",
    "action = vla.predict_action(**inputs, unnorm_key=\"bridge_orig\", do_sample=False)\n",
    "\n",
    "# 예측된 action 출력\n",
    "print(\"Predicted Action:\", action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00f5ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Action: [-1.55083277e-03  1.19467659e-03  2.78406746e-04  3.05409034e-03\n",
      " -2.62354567e-02  3.21692501e-02  9.96078431e-01]\n"
     ]
    }
   ],
   "source": [
    "image_path = \"/home/lab/Desktop/Screensho.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = \"In:Make a bounding box of what you see.\\nOut:\"\n",
    "\n",
    "# 프롬프트와 이미지를 모델 입력 형식으로 전처리 후 GPU로 이동 (dtype bf16)\n",
    "inputs = processor(prompt, image).to(\"cuda:0\", dtype=torch.bfloat16)\n",
    "\n",
    "# 모델을 이용해 action 예측\n",
    "action = vla.predict_action(**inputs, unnorm_key=\"bridge_orig\", do_sample=False)\n",
    "\n",
    "# 예측된 action 출력\n",
    "print(\"Predicted Action:\", action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0603b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
